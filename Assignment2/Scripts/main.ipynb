{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled successfully.\n",
      "age         0\n",
      "sex         0\n",
      "dataset     0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalch      0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "num         0\n",
      "dtype: int64\n",
      "    age  trestbps   chol  thalch  oldpeak  num  sex_Male  dataset_Hungary  \\\n",
      "0  63.0     145.0  233.0   150.0      2.3  0.0       1.0              0.0   \n",
      "1  67.0     160.0  286.0   108.0      1.5  2.0       1.0              0.0   \n",
      "2  67.0     120.0  229.0   129.0      2.6  1.0       1.0              0.0   \n",
      "3  37.0     130.0  250.0   187.0      3.5  0.0       1.0              0.0   \n",
      "4  41.0     130.0  204.0   172.0      1.4  0.0       0.0              0.0   \n",
      "\n",
      "   dataset_Switzerland  dataset_VA_Long_Beach  cp_atypical_angina  \\\n",
      "0                  0.0                    0.0                 0.0   \n",
      "1                  0.0                    0.0                 0.0   \n",
      "2                  0.0                    0.0                 0.0   \n",
      "3                  0.0                    0.0                 0.0   \n",
      "4                  0.0                    0.0                 1.0   \n",
      "\n",
      "   cp_non-anginal  cp_typical_angina  fbs_1.0  restecg_normal  \\\n",
      "0             0.0                1.0      1.0             0.0   \n",
      "1             0.0                0.0      0.0             0.0   \n",
      "2             0.0                0.0      0.0             0.0   \n",
      "3             1.0                0.0      0.0             1.0   \n",
      "4             0.0                0.0      0.0             0.0   \n",
      "\n",
      "   restecg_st-t_abnormality  exang_1.0  slope_flat  slope_upsloping  \n",
      "0                       0.0        0.0         0.0              0.0  \n",
      "1                       0.0        1.0         1.0              0.0  \n",
      "2                       0.0        1.0         1.0              0.0  \n",
      "3                       0.0        0.0         0.0              0.0  \n",
      "4                       0.0        0.0         0.0              1.0  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 1. Load the dataset\n",
    "heart_disease_uci = pd.read_csv('../Data/heart_disease_uci.csv')\n",
    "\n",
    "# 2. Examine the Dataset: Investigate the dataset before cleaning to find NA values, duplicates, etc.\n",
    "# heart_disease_uci.head()\n",
    "# heart_disease_uci.info()\n",
    "# heart_disease_uci.describe()\n",
    "# heart_disease_uci.tail()\n",
    "# heart_disease_uci.shape #dimensions\n",
    "# heart_disease_uci.columns\n",
    "heart_disease_uci.dtypes\n",
    "\n",
    "# 3. Preprocess the data\n",
    "# print(heart_disease_uci.isnull().sum())\n",
    "\n",
    "## A. drop duplicate rows\n",
    "heart_disease_uci = heart_disease_uci.drop_duplicates()  # Removes duplicate rows\n",
    "\n",
    "## B. Remove Redundant Features   \n",
    "def remove_na_features(data, threshold=0.5):\n",
    "    \"\"\"Remove redundant or duplicate columns.\n",
    "    :param data: pandas DataFrame\n",
    "    :param threshold: float, threshold percentage\n",
    "    :return: pandas DataFrame\n",
    "    \"\"\"\n",
    "    null_percent = data.isnull().mean() # to get the % of null values\n",
    "    # Drop columns with null percent greater than the threshold\n",
    "    to_drop = null_percent[null_percent > threshold].index\n",
    "    return data.drop(columns=to_drop)\n",
    "\n",
    "## Drop columns\n",
    "heart_disease_uci = remove_na_features(heart_disease_uci, threshold=0.5) # this will remove 'ca' and 'thal'\n",
    "\n",
    "## C. Imputate missing values\n",
    "def impute_missing_values(data, strategy='mean'):\n",
    "    \"\"\"\n",
    "    Fill missing values in the dataset.\n",
    "    :param data: pandas DataFrame\n",
    "    :param strategy: str, imputation method ('mean', 'median', 'mode')\n",
    "    :return: pandas DataFrame\n",
    "    \"\"\"    \n",
    "    # Isolate numerical columns from the dataset to account for TypeError\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    cat_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "    if strategy == \"mean\":\n",
    "        data[num_cols] = data[num_cols].fillna(data[num_cols].mean()) # NA values replaced with the mean of the column\n",
    "    elif strategy == \"median\":\n",
    "        data[num_cols] = data[num_cols].fillna(data[num_cols].median()) # NA values replaced with the median of the column\n",
    "    elif strategy == \"mode\":\n",
    "        for col in num_cols:\n",
    "            data[col] = data[col].fillna(data[col].mode().iloc[0]) # iloc[0] takes the first value as mode\n",
    "    else:\n",
    "        raise ValueError(\"Invalid strategy! Please choose either Mean, Median, or Mode.\")\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        data[col] = data[col].astype('category')\n",
    "        data[col] = data[col].fillna(data[col].mode().iloc[0]) # iloc[0] takes the first value as mode\n",
    "    \n",
    "    return data\n",
    "\n",
    "heart_disease_uci = impute_missing_values(heart_disease_uci, strategy='mean')\n",
    "print(\"Missing values handled successfully.\")\n",
    "print(heart_disease_uci.isnull().sum()) # every column returns 0 now\n",
    "\n",
    "\n",
    "## D. Convert categorical features to numerical - ONE HOT ENCODING\n",
    "# isolate categorical columns again\n",
    "cat_columns = heart_disease_uci.select_dtypes(include=['category']).columns \n",
    "\n",
    "# apply One-Hot Encoding steps\n",
    "# initializing OneHotEncoder\n",
    "onehot = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' column to avoid multicollinearity and redundancy\n",
    "encoded_data = onehot.fit_transform(heart_disease_uci[cat_columns])\n",
    "\n",
    "# create the encoded data DataFrame and add column names using OneHotEncoder\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=onehot.get_feature_names_out(cat_columns))\n",
    "encoded_df.columns = [col.replace(\" \", \"_\") for col in encoded_df.columns] # to remove spaces in some column names\n",
    "\n",
    "# Concatenate the original DataFrame with the encoded DataFrame, dropping the original categorical columns\n",
    "heart_disease_encoded = pd.concat([heart_disease_uci.drop(columns=cat_columns), encoded_df], axis=1)\n",
    "print(heart_disease_encoded.head()) # print to check\n",
<<<<<<< Updated upstream
    "\n"
   ]
  },
  
=======
    "\n",
    "#4 Build Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> Stashed changes
